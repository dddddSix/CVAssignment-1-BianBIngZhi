{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision: 0.75\n",
      "Mean Recall: 0.15\n",
      "Mean F1-Score: 0.25\n",
      "Time taken for text detection on 1000 samples: 82.15 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pytesseract\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "# Update the Tesseract path (if needed)\n",
    "pytesseract.pytesseract.tesseract_cmd = (\n",
    "    r\"C:\\Users\\shiku\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_ground_truth(gt_file):\n",
    "    \"\"\"Load ground truth bounding boxes from ICDAR2015 label files.\"\"\"\n",
    "    boxes = []\n",
    "    with open(gt_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split(\",\")\n",
    "            coords = list(map(int, parts[:8]))  # Get the 8 coordinates\n",
    "            box = [(coords[i], coords[i + 1]) for i in range(0, len(coords), 2)]\n",
    "            boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def decode_predictions(scores, geometry, confThreshold=0.5):\n",
    "    \"\"\"Decode predictions from the EAST model into bounding boxes.\"\"\"\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    for y in range(numRows):\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        for x in range(numCols):\n",
    "            if scoresData[x] < confThreshold:\n",
    "                continue\n",
    "\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "            angle = anglesData[x]\n",
    "            cos, sin = np.cos(angle), np.sin(angle)\n",
    "\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "\n",
    "    return rects, confidences\n",
    "\n",
    "\n",
    "def compute_iou(boxA, boxB):\n",
    "    \"\"\"Compute Intersection over Union (IoU) between two boxes.\"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # Compute the area of intersection\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # Compute the area of both the predicted and ground-truth rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # Compute the IoU\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def match_boxes(pred_boxes, gt_boxes, iou_threshold=0.2):\n",
    "    \"\"\"Match predicted boxes with ground truth using IoU.\"\"\"\n",
    "    matches = 0\n",
    "    used = [False] * len(gt_boxes)  # Track matched ground-truth boxes\n",
    "\n",
    "    for pred in pred_boxes:\n",
    "        for i, gt in enumerate(gt_boxes):\n",
    "            if not used[i] and compute_iou(pred, gt) >= iou_threshold:\n",
    "                matches += 1\n",
    "                used[i] = True  # Mark this GT box as matched\n",
    "                break\n",
    "\n",
    "    return matches\n",
    "\n",
    "\n",
    "def detect_and_evaluate(\n",
    "    image_path, net, gt_file=None, apply_gray=True, apply_blur=True\n",
    "):\n",
    "    \"\"\"Detect text and evaluate bounding box detection.\"\"\"\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image {image_path}\")\n",
    "        return 0, 0, 0\n",
    "    orig = image.copy()\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # Optionally apply grayscale and Gaussian blur\n",
    "    if apply_gray:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Ensure 3 channels\n",
    "    if apply_blur:\n",
    "        image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Resize the image for the EAST model\n",
    "    newW, newH = 320, 320\n",
    "    rW, rH = w / float(newW), h / float(newH)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        image, 1.0, (newW, newH), (123.68, 116.78, 103.94), swapRB=True, crop=False\n",
    "    )\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Run the model and decode predictions\n",
    "    layerNames = [\"feature_fusion/Conv_7/Sigmoid\", \"feature_fusion/concat_3\"]\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "    (rects, confidences) = decode_predictions(scores, geometry, confThreshold=0.1)\n",
    "    pred_boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "\n",
    "    # Scale the bounding boxes back to the original image size\n",
    "    pred_boxes = [\n",
    "        (int(x * rW), int(y * rH), int(x2 * rW), int(y2 * rH))\n",
    "        for (x, y, x2, y2) in pred_boxes\n",
    "    ]\n",
    "\n",
    "    # print(f\"Number of predicted boxes: {len(pred_boxes)}\")\n",
    "\n",
    "    if gt_file:\n",
    "        # Load ground truth boxes\n",
    "        gt_boxes = load_ground_truth(gt_file)\n",
    "        # print(f\"Number of ground truth boxes: {len(gt_boxes)}\")\n",
    "\n",
    "        # Flatten ground truth boxes to (x1, y1, x2, y2) format\n",
    "        gt_boxes = [\n",
    "            (\n",
    "                min(pt[0] for pt in x),\n",
    "                min(pt[1] for pt in x),\n",
    "                max(pt[0] for pt in x),\n",
    "                max(pt[1] for pt in x),\n",
    "            )\n",
    "            for x in gt_boxes\n",
    "        ]\n",
    "\n",
    "        # Match predicted and ground truth boxes\n",
    "        matches = match_boxes(pred_boxes, gt_boxes)\n",
    "        return matches, len(pred_boxes), len(gt_boxes)\n",
    "\n",
    "    return 0, 0, 0\n",
    "\n",
    "\n",
    "# Load the EAST model\n",
    "east_model = \"frozen_east_text_detection.pb\"\n",
    "net = cv2.dnn.readNet(east_model)\n",
    "\n",
    "# Define dataset paths\n",
    "input_folder = \"icdar2015dataset/ch4_training_images\"\n",
    "gt_folder = \"icdar2015dataset/ch4_training_localization_transcription_gt\"\n",
    "\n",
    "# Performance evaluation on the first 1000 samples\n",
    "start_time = time.time()\n",
    "total_matches = total_pred = total_gt = 0\n",
    "\n",
    "for idx, filename in enumerate(os.listdir(input_folder)):\n",
    "    if idx >= 1000:\n",
    "        break  # Process only the first 1000 samples\n",
    "\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        gt_file = os.path.join(gt_folder, f\"gt_{filename.replace('.jpg', '.txt')}\")\n",
    "        try:\n",
    "            matches, pred_count, gt_count = detect_and_evaluate(\n",
    "                image_path, net, gt_file, apply_gray=True, apply_blur=True\n",
    "            )\n",
    "            total_matches += matches\n",
    "            total_pred += pred_count\n",
    "            total_gt += gt_count\n",
    "        except Exception as e:\n",
    "            print(f\"Error when processing {image_path}: {e}\")\n",
    "\n",
    "# Compute precision, recall, and F1 score for bounding box detection\n",
    "precision = total_matches / total_pred if total_pred > 0 else 0\n",
    "recall = total_matches / total_gt if total_gt > 0 else 0\n",
    "f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Display results\n",
    "print(f\"Mean Precision: {precision:.2f}\")\n",
    "print(f\"Mean Recall: {recall:.2f}\")\n",
    "print(f\"Mean F1-Score: {f1:.2f}\")\n",
    "print(f\"Time taken for text detection on 1000 samples: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Threshold =0.1\n",
    "    Mean Precision: 0.75\n",
    "    Mean Recall: 0.15\n",
    "    Mean F1-Score: 0.25\n",
    "    Time taken for text detection on 1000 samples: 80.49 seconds\n",
    "- Threshold =0.5\n",
    "    Mean Precision: 0.78\n",
    "    Mean Recall: 0.14\n",
    "    Mean F1-Score: 0.24\n",
    "    Time taken for text detection on 1000 samples: 78.85 seconds\n",
    "- Threshold =0.8\n",
    "    Mean Precision: 0.80\n",
    "    Mean Recall: 0.14\n",
    "    Mean F1-Score: 0.23\n",
    "    Time taken for text detection on 1000 samples: 79.59 seconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with confThreshold=0.1\n",
    "- No preprocessing\n",
    "    Mean Precision: 0.78\n",
    "    Mean Recall: 0.18\n",
    "    Mean F1-Score: 0.30\n",
    "    Time taken for text detection on 1000 samples: 81.88 seconds\n",
    "- Grayscale\n",
    "    Mean Precision: 0.73\n",
    "    Mean Recall: 0.17\n",
    "    Mean F1-Score: 0.27\n",
    "    Time taken for text detection on 1000 samples: 78.82 seconds\n",
    "- Blur\n",
    "    Mean Precision: 0.80\n",
    "    Mean Recall: 0.16\n",
    "    Mean F1-Score: 0.27\n",
    "    Time taken for text detection on 1000 samples: 79.97 seconds\n",
    "- Grayscale + Blur\n",
    "    Mean Precision: 0.75\n",
    "    Mean Recall: 0.15\n",
    "    Mean F1-Score: 0.25\n",
    "    Time taken for text detection on 1000 samples: 80.49 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with confThreshold=0.1\n",
    "- No preprocessing\n",
    "    Mean Precision: 0.78\n",
    "    Mean Recall: 0.18\n",
    "    Mean F1-Score: 0.30\n",
    "    Time taken for text detection on 1000 samples: 81.88 seconds\n",
    "- Grayscale\n",
    "    Mean Precision: 0.73\n",
    "    Mean Recall: 0.17\n",
    "    Mean F1-Score: 0.27\n",
    "    Time taken for text detection on 1000 samples: 78.82 seconds\n",
    "- Blur\n",
    "    Mean Precision: 0.73\n",
    "    Mean Recall: 0.17\n",
    "    Mean F1-Score: 0.27\n",
    "    Time taken for text detection on 1000 samples: 78.82 seconds\n",
    "- Grayscale + Blur\n",
    "    Mean Precision: 0.75\n",
    "    Mean Recall: 0.15\n",
    "    Mean F1-Score: 0.25\n",
    "    Time taken for text detection on 1000 samples: 80.49 seconds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
